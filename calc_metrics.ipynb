{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847a7c1b-3f04-49dc-9a4f-9189d6118e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdsmeyanov/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/mdsmeyanov/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from ct_model_class import Model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms.v2 import Resize\n",
    "import math\n",
    "from numba import njit, prange\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision.transforms import ToPILImage\n",
    "import glob\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ebca39-2cfa-4964-a7c6-94595ff7996f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_model(arr, model):\n",
    "    img = np.array(arr, dtype = float) \n",
    "    img = (img - img.min()) / (img.max() - img.min()) * 255.0  \n",
    "    img = img.astype(np.uint8)\n",
    "    img = np.expand_dims(img, 2)\n",
    "    img = np.dstack((img, img[:, :, 0], img[:, :, 0]))\n",
    "\n",
    "    aorta, arterial = model.process_images(img)\n",
    "    \n",
    "    if aorta[1].item() > 9.5 and arterial[1].item() > 9.5:\n",
    "        return aorta, arterial, True\n",
    "    return None, None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43d9a04-7630-43d3-a0d7-87888ef59c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def take_aorta_diameter(image):\n",
    "    area_in_pixels = 0\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[0])):\n",
    "            # print(image[i][j])\n",
    "            if image[i][j] > 50:\n",
    "                area_in_pixels += 1\n",
    "    diameter = math.sqrt(area_in_pixels/math.pi)\n",
    "    \n",
    "    display(Image.fromarray(crop_image(image)))\n",
    "\n",
    "    return diameter*2\n",
    "\n",
    "@njit(parallel=True, fastmath=True)\n",
    "def check_mask_width_numba(image):\n",
    "    # it is enough to check just one channel, since images are black-white\n",
    "    max_width = 0\n",
    "    for i in prange(len(image)):\n",
    "        cur_width = 0\n",
    "        for j in range(len(image[0])):\n",
    "            if image[i][j] != 0:\n",
    "                cur_width += 1\n",
    "        if cur_width > max_width:\n",
    "            max_width = cur_width\n",
    "    return max_width\n",
    "\n",
    "\n",
    "def crop_image(image):\n",
    "    first_row = -1\n",
    "    last_row = -1\n",
    "    for i in range(len(image)):\n",
    "        some_image = False\n",
    "        for j in range(len(image[0])):\n",
    "            if image[i][j] > 20:\n",
    "                some_image = True\n",
    "                break\n",
    "        if some_image and first_row == -1:\n",
    "            first_row = i\n",
    "        if not(some_image) and first_row != -1 and last_row == -1:\n",
    "            last_row = i\n",
    "            break\n",
    "            \n",
    "    first_column = -1\n",
    "    last_column = -1\n",
    "    for i in range(len(image[0])):\n",
    "        some_image = False\n",
    "        for j in range(len(image)):\n",
    "            if image[j][i] > 20:\n",
    "                some_image = True\n",
    "                break\n",
    "        if some_image and first_column == -1:\n",
    "            first_column = i\n",
    "        if not(some_image) and first_column != -1 and last_column == -1:\n",
    "            last_column = i\n",
    "            break\n",
    "            \n",
    "    return image[first_row:last_row, first_column:last_column]\n",
    "                \n",
    "def find_highest_black_peak(image):\n",
    "    heights = [0]*len(image[0])\n",
    "    total_finished = 0\n",
    "    for i in range(len(image)-1, 0, -1):\n",
    "        for j in range(len(image[0])):\n",
    "            if image[i][j] < 20 and heights[j] != -1:\n",
    "                # print(i, j)\n",
    "                heights[j] += 1\n",
    "            elif heights[j] != -1:\n",
    "                if total_finished == len(image[0])-1:\n",
    "                    return i\n",
    "                heights[j] = -1\n",
    "                total_finished += 1\n",
    "    return 0\n",
    "\n",
    "                \n",
    "\n",
    "def take_diameter(image, height):\n",
    "    width = 0\n",
    "    for i in range(len(image[0])):\n",
    "        if height-10 > 0:\n",
    "            if image[height-10][i] < 100 and width > 0:\n",
    "                return width\n",
    "            elif image[height-10][i] > 100:\n",
    "                width += 1\n",
    "        elif height-5 > 0:\n",
    "            if image[height-5][i] < 100 and width > 0:\n",
    "                return width\n",
    "            elif image[height-5][i] > 100:\n",
    "                width += 1\n",
    "        else:\n",
    "            if image[height][i] < 100 and width > 0:\n",
    "                return width\n",
    "            elif image[height][i] > 100:\n",
    "                width += 1\n",
    "        \n",
    "    return width\n",
    "\n",
    "\n",
    "def take_arterial_diameter(image):\n",
    "    max_width = 0\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    for rotation_angle in range(30):\n",
    "        image_rotated = torchvision.transforms.functional.rotate(img=image, angle=rotation_angle)\n",
    "        image_rotated_np = np.array(image_rotated)\n",
    "        image_rotated_np_flattened = image_rotated_np.flatten()\n",
    "        white_width = check_mask_width_numba(image_rotated_np)\n",
    "        if white_width > max_width:\n",
    "            max_width = white_width\n",
    "            final_angle = rotation_angle\n",
    "\n",
    "\n",
    "    image = torchvision.transforms.functional.rotate(img=image, angle=rotation_angle)\n",
    "\n",
    "    image_cropped = crop_image(np.array(image))\n",
    "    height = find_highest_black_peak(image_cropped)\n",
    "    # color height where diameter is taken\n",
    "    diameter = take_diameter(image_cropped, height)\n",
    "    for i in range(len(image_cropped[height])):\n",
    "        image_cropped[height-10][i] = 1\n",
    "    display(Image.fromarray(image_cropped))\n",
    "    return diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2531e84-0fef-4a5d-8df4-7bd7dc1072de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'76619-22': 'ЛАГ-СЗСТ',\n",
       " '89328-22': 'ИЛАГ',\n",
       " '92878-22': 'ЛАГ-СЗСТ',\n",
       " '90126-22': 'Болезнь Рандю-Ослера',\n",
       " '14459-23': 'Болезнь Рандю-Ослера',\n",
       " '320-23': 'Болезнь Рандю-Ослера',\n",
       " '66332-22': 'ХТЭЛГ',\n",
       " '47931-22': 'ИЛАГ',\n",
       " '72688-22': 'ХТЭЛГ',\n",
       " '74710-22': 'ЛАГ-СЗСТ',\n",
       " '74340-22': 'ХТЭЛГ',\n",
       " '77580-22': 'ЛАГ-СЗСТ',\n",
       " '79358-22': 'ХТЭЛГ',\n",
       " '76633-22': 'ХТЭЛГ',\n",
       " '81046-22': 'ИЛАГ',\n",
       " '88812-22': 'ИЛАГ',\n",
       " '92597-22': 'ХТЭЛГ',\n",
       " '90398-22': 'ИЛАГ',\n",
       " '92285-22': 'ХТЭЛГ',\n",
       " '97867-22': 'ХТЭЛГ',\n",
       " '4633-23': 'ИЛАГ',\n",
       " '105671-22': 'ИЛАГ',\n",
       " '7234-22': 'ХТЭЛГ',\n",
       " '11374-23': 'ЛАГ-СЗСТ',\n",
       " '12831-23': 'ЛАГ-СЗСТ',\n",
       " '11393-23': 'ХТЭЛГ',\n",
       " '17397-23': 'ИЛАГ',\n",
       " '23072-23': 'ИЛАГ',\n",
       " '21460-23': 'Болезнь Рандю-Ослера',\n",
       " '22625-23': 'ХТЭЛГ',\n",
       " '36639-23': 'ИЛАГ',\n",
       " '37113-23': 'ИЛАГ',\n",
       " '44704-23': 'ХТЭЛГ',\n",
       " '47704-23': 'ИЛАГ',\n",
       " '39311-23': 'ХТЭЛГ',\n",
       " '13274-23': 'ХТЭЛГ'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('list1.txt', 'rb') as f:\n",
    "    diseases = f.readlines()\n",
    "patient_disease_pairs = list(map(lambda x: x.decode('cp1251').split('\\t')[2:4], diseases))\n",
    "\n",
    "diseases = {}\n",
    "for patient_disease in patient_disease_pairs:\n",
    "    if patient_disease[0] == \"История болезни\":\n",
    "        continue\n",
    "    diseases[patient_disease[0]] = patient_disease[1].split(\"\\r\")[0]\n",
    "diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4306cb6-e8b0-4e3c-b7f9-33aaa5623397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = ToPILImage()\n",
    "model = Model()\n",
    "for patient in diseases.keys():\n",
    "    print(diseases[patient])\n",
    "    max_ratio = 0\n",
    "    files = os.listdir(f'med1/{patient}/')\n",
    "    for file in tqdm(files, position=0, leave=True):\n",
    "        data = pydicom.dcmread((f'med1/{patient}/' + file))\n",
    "        arr = data.pixel_array\n",
    "        if len(arr.shape) == 2:\n",
    "            aorta, arterial, confidence = apply_model(arr, model)\n",
    "            if confidence:\n",
    "                print(take_arterial_diameter(arterial[0])/take_aorta_diameter(aorta[0]))\n",
    "        if len(arr.shape) == 3:\n",
    "            for i in tqdm(range(0, len(arr)), position=0, leave=True):\n",
    "                aorta, arterial, confidence = apply_model(arr[i], model)\n",
    "                if confidence:\n",
    "                    ratio = take_arterial_diameter(arterial[0])/take_aorta_diameter(aorta[0])\n",
    "                    print(ratio)\n",
    "                    if ratio > max_ratio:\n",
    "                        max_ration = ratio\n",
    "    if max_ratio > 1.0:\n",
    "        print('pulmonary hypertension detected')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
